<div align='center'>
    <img src="./images/header.svg" alt="alt text" width="100%">
    <h1>ğŸ’» handy-ollama ğŸ¦™</h1>
</div>

<div align="center">
  <img src="https://img.shields.io/github/stars/datawhalechina/handy-ollama?style=for-the-badge&logo=github" alt="GitHub stars"/>
  <img src="https://img.shields.io/github/forks/datawhalechina/handy-ollama?style=for-the-badge&logo=github" alt="GitHub forks"/>
  <img src="https://img.shields.io/github/issues/datawhalechina/handy-ollama?style=for-the-badge&logo=github" alt="GitHub issues"/>
  <img src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-brightgreen?style=for-the-badge" alt="GitHub license"/>
</div>

<div align="center">
  <h3>ğŸ“š Master Large Model Deployment on CPU from Scratch!</h3>
  <p><em>Learn Ollama Hands-On: Fast Local Deployment of Large Language Models</em></p>
</div>

[ç®€ä½“ä¸­æ–‡](README.md) | English

## ğŸš€ Introduction
A hands-on tutorial series for Ollama, designed to simplify the process of deploying large language models locally. With this guide, you'll be able to manage and run powerful LLMs right on your CPU, making advanced AI accessible without GPU dependencies!

Our comprehensive tutorial covers everything from beginner basics to advanced usage, complete with real-world examples that demonstrate practical applications of LLM deployment. Whether you're a complete novice or an experienced developer, our step-by-step instructions and practical tips will help you master Ollama and start building your own LLM-powered applications.

### Key Topics Covered:
1. **Introduction, Installation & Configuration**: 
   - macOS, Windows, Linux, and Docker deployment guides.
2. **Custom Model Integration**:
   - Import from GGUF, PyTorch, Safetensors, and custom prompt engineering.
3. **Ollama REST API**:
   - Comprehensive usage guide with examples in Python, Java, JavaScript, and C++.
4. **LangChain Integration**:
   - Seamless integration with Python and JavaScript workflows.
5. **Visual Interfaces & Use Cases**:
   - Build interactive chat UIs with FastAPI and WebUI, plus practical RAG and Agent applications.

**We warmly welcome contributions!** Submit issues or pull requests to help improve this project. Let's make advanced AI accessible to everyone!

**Our Mission**: Empower every LLM enthusiast to explore and experiment, regardless of programming background or computational resources. We're breaking down technical barriers to make LLM deployment achievable on personal computers. Join us on this exciting journey!


### Directory Structure:

```
docs ---------------------- Markdown documentation files
notebook ------------------ Notebook source code and Python/Java/JavaScript examples
images -------------------- Image assets
```

ğŸ“– **Read Online**: https://datawhalechina.github.io/handy-ollama/  


## âš ï¸ Security Notice

<details>
  <summary>
   <a href="https://mp.weixin.qq.com/s/n7PyLykK7MlO3re2oOyY5w">Security Advisory: Ollama's Default Configuration Risks</a>
  </summary>

According to the Tsinghua University Cyberspace Mapping Joint Research Center, the open-source cross-platform LLM tool Ollama has security vulnerabilities in its default configuration, including unauthorized access and model theft risks. Given the widespread use of models like DeepSeek deployed via Ollama in private environments without configuration changes, users face risks of data leakage, unauthorized resource usage, and service disruptions.

### Key Risks:
1. **Unauthorized Access**: 
   - Default configuration exposes port 11434 without authentication. Attackers can access models, execute commands, and steal sensitive data.
2. **Data Leakage**: 
   - Sensitive information (e.g., model licenses, parameters) can be extracted via unprotected API endpoints.
3. **Exploitable Vulnerabilities**: 
   - Historical vulnerabilities (CVE-2024-39720/39722/39719/39721) allow data poisoning, parameter theft, and malicious file operations.

### Security Recommendations:
1. **Restrict Network Access**: 
   - Configure Ollama to listen only on localhost and verify port settings.
2. **Firewall Configuration**: 
   - Block public access to port 11434 usingåŒå‘ç«¯å£è¿‡æ»¤.
3. **Enable Authentication**: 
   - Use API keys, rate limiting, and IP whitelisting.
4. **Disable Risky APIs**: 
   - Restrict or disable endpoints like `/push`, `/delete`, and `/pull`.
5. **Update Regularly**: 
   - Keep Ollama updated to patch known vulnerabilities.

We strongly recommend users audit their Ollama deployments, apply these security measures, and report any suspicious activity to local cybersecurity authorities. The National Cybersecurity Information Sharing Center will continue monitoring and issuing updates.
</details>


## ğŸ’¡ Motivation
The rapid growth of open-source LLMs has democratized AI, but many require GPU resources for deployment. Our goal is to make LLM technology accessible to everyoneâ€”regardless of hardware limitationsâ€”using Ollama, an open-source tool that enables CPU-based deployment of powerful language models.

This tutorial series empowers learners, hobbyists, and developers to deploy and experiment with LLMs locally, fostering innovation across industries.


## ğŸ¯ Target Audience
- **Resource-Constrained Users**: Run LLMs locally without GPU dependencies.
- **Developers**: Build and test LLM-powered applications on consumer hardware.
- **AI Enthusiasts**: Experiment with state-of-the-art models without cloud costs.
- **Privacy-Conscious Users**: Keep sensitive data and model operations local.


## âœ¨ Highlights
While many LLM tutorials rely on GPU acceleration, this project focuses exclusively on **CPU-based deployment**, making advanced AI accessible to anyone with a modern computer. Through hands-on examples and clear explanations, we bridge the gap between theory and practice.


## ğŸ“– Roadmap
### Table of Contents (Work in Progress)
- [x] 1 [Ollama Introduction](docs/C1/1.%20Ollama%20ä»‹ç».md) @[Youdon](https://github.com/AXYZdong)
- [x] 2 Ollama Installation & Configuration 
  - [x] [macOS](docs/C2/1.%20Ollama%20åœ¨%20macOS%20ä¸‹çš„å®‰è£…ä¸é…ç½®.md) @[å¤©å¥¥](https://github.com/lta155)
  - [x] [Windows](docs/C2/2.%20Ollama%20åœ¨%20Windows%20ä¸‹çš„å®‰è£…ä¸é…ç½®.md) @[Yuki](https://github.com/fuyueagain)
  - [x] [Linux](docs/C2/3.%20Ollama%20åœ¨%20Linux%20ä¸‹çš„å®‰è£…ä¸é…ç½®.md) @[Yuki](https://github.com/fuyueagain)
  - [x] [Docker](docs/C2/4.%20Ollama%20åœ¨%20Docker%20ä¸‹çš„å®‰è£…ä¸é…ç½®.md) @[Yuki](https://github.com/fuyueagain)
- [x] 3 Custom Ollama Usage
  - [x] [Custom Model Import](docs/C3/1.%20è‡ªå®šä¹‰å¯¼å…¥æ¨¡å‹.md) @[æ¨å“](https://github.com/little1d)
  - [x] [Custom Model Storage](docs/C3/2.%20è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ä½ç½®.md) @[Yuki](https://github.com/fuyueagain) @[æ—é€š](https://github.com/kjlintong) @[å¤©å¥¥](https://github.com/lta155)
  - [x] [GPU Configuration](docs/C3/3.%20è‡ªå®šä¹‰åœ¨%20GPU%20ä¸­è¿è¡Œ.md) @[Youdon](https://github.com/AXYZdong)
- [x] 4 Ollama REST API
  - [x] [API Guide](docs/C4/1.%20Ollama%20API%20ä½¿ç”¨æŒ‡å—.md) @[æ—é€š](https://github.com/kjlintong) @[æ˜¥é˜³](https://github.com/Springff)
  - [x] [Python Integration](docs/C4/2.%20åœ¨%20Python%20ä¸­ä½¿ç”¨%20Ollama%20API.md) @[æ˜¥é˜³](https://github.com/Springff)
  - [x] [Java Integration](docs/C4/3.%20åœ¨%20Java%20ä¸­ä½¿ç”¨%20Ollama%20API.md) @[æ—é€š](https://github.com/kjlintong)
  - [x] [JavaScript Integration](docs/C4/4.%20åœ¨%20JavaScript%20ä¸­ä½¿ç”¨%20Ollama%20API.md) @[æ˜¥é˜³](https://github.com/Springff)
  - [x] [C++ Integration](docs/C4/5.%20åœ¨%20C++%20ä¸­ä½¿ç”¨%20Ollama%20API.md) @[æ—é€š](https://github.com/kjlintong)
  - [x] [Golang Integration](docs/C4/6.%20åœ¨%20Golang%20ä¸­ä½¿ç”¨%20Ollama%20API.md) @[tomowang](https://github.com/tomowang)
  - [ ] C# Integration (To be updated)
  - [ ] Rust Integration (To be updated)
  - [ ] Ruby Integration (To be updated)
  - [ ] R Integration (To be updated)
- [x] 5 Ollama with LangChain
    - [x] [Python Integration](docs/C5/1.%20Ollama%20åœ¨%20LangChain%20ä¸­çš„ä½¿ç”¨%20-%20Python%20é›†æˆ.md) @[é‘«æ°‘](https://github.com/fancyboi999)
    - [x] [JavaScript Integration](docs/C5/2.%20Ollama%20åœ¨%20LangChain%20ä¸­çš„ä½¿ç”¨%20-%20JavaScript%20é›†æˆ.md) @[é‘«æ°‘](https://github.com/fancyboi999)
- [x] 6 Ollama Visual Interfaces
    - [x] [FastAPI-based Chat UI](docs/C6/1.%20ä½¿ç”¨%20FastAPI%20éƒ¨ç½²%20Ollama%20å¯è§†åŒ–å¯¹è¯ç•Œé¢.md) @[Youdon](https://github.com/AXYZdong)
    - [x] [WebUI-based Chat UI](docs/C6/2.%20ä½¿ç”¨%20WebUI%20éƒ¨ç½²%20Ollama%20å¯è§†åŒ–å¯¹è¯ç•Œé¢.md) @[Youdon](https://github.com/AXYZdong)
- [ ] 7 Use Cases
    - [x] [Local AI Copilot](docs/C7/1.%20æ­å»ºæœ¬åœ°çš„%20AI%20Copilot%20ç¼–ç¨‹åŠ©æ‰‹.md) @[è¶Š](https://github.com/rainsubtime)
    - [x] [Dify Integration](docs/C7/2.%20Dify%20æ¥å…¥%20Ollama%20éƒ¨ç½²çš„æœ¬åœ°æ¨¡å‹.md) @[æ˜¥é˜³](https://github.com/Springff)
    - [x] [LangChain RAG App](docs/C7/3.%20ä½¿ç”¨%20LangChain%20æ­å»ºæœ¬åœ°%20RAG%20åº”ç”¨.md) @[èˆ’å‡¡](https://github.com/Tsumugii24)
    - [x] [LlamaIndex RAG App](docs/C7/4.%20ä½¿ç”¨%20LlamaIndex%20æ­å»ºæœ¬åœ°%20RAG%20åº”ç”¨.md) @[Youdon](https://github.com/AXYZdong)
    - [x] [LangChain Agent](docs/C7/5.%20ä½¿ç”¨%20LangChain%20å®ç°æœ¬åœ°%20Agent.md) @[Youdon](https://github.com/AXYZdong)
    - [x] [LlamaIndex Agent](docs/C7/6.%20ä½¿ç”¨%20LlamaIndex%20å®ç°æœ¬åœ°%20Agent.md) @[Youdon](https://github.com/AXYZdong)
    - [x] [DeepSeek R1 RAG App](docs/C7/7.%20ä½¿ç”¨%20DeepSeek%20R1%20å’Œ%20Ollama%20å®ç°æœ¬åœ°%20RAG%20åº”ç”¨.md) @[Youdon](https://github.com/AXYZdong)
    - [ ] More to come...


**Note**: We welcome contributions to complete the pending sections! Submit issues or pull requests to help expand this project.

**Interested in becoming a maintainer?** Contact us to join our core team!


## ğŸ™ Acknowledgments

Official Ollama Repository: https://github.com/ollama/ollama  

Special thanks to our contributors!

<a href="https://github.com/AXYZdong/handy-ollama/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=AXYZdong/handy-ollama" />
</a>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=datawhalechina/handy-ollama&type=Date)](https://star-history.com/#datawhalechina/handy-ollama&Date)

## LICENSE

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="çŸ¥è¯†å…±äº«è®¸å¯åè®®" style="border-width:0" src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.